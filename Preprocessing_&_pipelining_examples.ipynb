{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJr_9dXGpJ05",
        "outputId": "beb4aaca-6eac-4b30-f2ff-ea4308968122"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "86400"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seconds_in_a_day = 24 * 60 * 60\n",
        "seconds_in_a_day"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gE-Ez1qtyIA",
        "outputId": "e8f0c2b1-3c1e-4476-f8c2-d8f31cdb5e75"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "604800"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seconds_in_a_week = 7 * seconds_in_a_day\n",
        "seconds_in_a_week"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "X = np.array([[1, 2000],\n",
        "              [2, 3000],\n",
        "              [3, 4000]])\n",
        "\n",
        "\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "print(X_scaled)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOmLDWJ-DUar",
        "outputId": "ba4fa43f-a79b-4847-c0ab-da84d091485b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.  0. ]\n",
            " [0.5 0.5]\n",
            " [1.  1. ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "X = np.array([[1, 2000],\n",
        "              [2, 3000],\n",
        "              [3, 4000]])\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "print(X_scaled)\n"
      ],
      "metadata": {
        "id": "QCDRXXahEAHr",
        "outputId": "f33103a6-5b81-42a9-ed99-82a4fb84671c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.22474487 -1.22474487]\n",
            " [ 0.          0.        ]\n",
            " [ 1.22474487  1.22474487]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import Normalizer\n",
        "import numpy as np\n",
        "\n",
        "X = np.array([[1, 2000],\n",
        "              [2, 3000],\n",
        "              [3, 4000]])\n",
        "\n",
        "scaler = Normalizer()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "print(X_scaled)\n",
        "\n"
      ],
      "metadata": {
        "id": "9SNyxT54EVi7",
        "outputId": "43d81d21-f412-463b-b55b-46da28adbcf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4.99999938e-04 9.99999875e-01]\n",
            " [6.66666519e-04 9.99999778e-01]\n",
            " [7.49999789e-04 9.99999719e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split into training/testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),               # Step 1: scale features\n",
        "    ('model', LogisticRegression(max_iter=200)) # Step 2: fit model\n",
        "])\n",
        "\n",
        "# Fit pipeline on training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "PiiGrAAbFzrp",
        "outputId": "05b53fb5-360f-4a63-a831-1dce35c35ae8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),               # Step 1: scale features (optional for RF)\n",
        "    ('model', RandomForestClassifier(n_estimators=100, random_state=42))  # Step 2: train model\n",
        "])\n",
        "\n",
        "# Fit the pipeline\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "KF6p2wbmGV7v",
        "outputId": "b368412a-b0af-4b00-e55e-972e730e2e91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Simulated mix of numeric + categorical features\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Sample data with mixed types\n",
        "data = pd.DataFrame({\n",
        "    'age': [25, 32, 47, 51, 62, 23],\n",
        "    'income': [50000, 60000, 85000, 90000, 120000, 45000],\n",
        "    'education': ['Bachelor', 'Master', 'PhD', 'PhD', 'Bachelor', 'High School'],\n",
        "    'target': [0, 1, 1, 1, 0, 0]\n",
        "})\n",
        "\n",
        "# Features and target\n",
        "X = data.drop('target', axis=1)\n",
        "y = data['target']\n",
        "\n",
        "# Identify feature types\n",
        "numeric_features = ['age', 'income']\n",
        "categorical_features = ['education']\n",
        "\n",
        "# Preprocessing for columns\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numeric_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ])\n",
        "\n",
        "# Create pipeline with preprocessing and model\n",
        "pipeline = Pipeline([\n",
        "    ('preprocess', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
        "])\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Fit and predict\n",
        "pipeline.fit(X_train, y_train)\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print\""
      ],
      "metadata": {
        "id": "31FURdYGHR1G",
        "outputId": "20e5695c-03d8-4c64-d5b5-55cff8b8442e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}